<!doctype html><html class="theme-next mist use-motion" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="evAx-EdEyUEd-j9zqy2DLYlZNcDZYig2uwZF6K6SOSU"><meta name="baidu-site-verification" content="PqQ6XK9DFN"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css"><meta name="keywords" content="Python,Scrapy,"><link rel="alternate" href="/atom.xml" title="那小子真帅" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1"><meta name="description" content="自己不牛逼，认识的人再多也没用  爬取动态页面静态页面的内容始终不变，爬取相对容易，但在现实中，日前绝大多数网站的页面都是动态页面。动态页面中的部分内容是浏览器运行页面中的 JavaScript 脚本动态生成的，爬取相对困难。先来看一个简单的动态页面的例子，在浏览器中打开 Quotes"><meta name="keywords" content="Python,Scrapy"><meta property="og:type" content="article"><meta property="og:title" content="精通 Scrapy 网络爬虫（三）"><meta property="og:url" content="http://blog.dongfei.xin/2018-04-01/精通 Scrapy 网络爬虫（三）/index.html"><meta property="og:site_name" content="那小子真帅"><meta property="og:description" content="自己不牛逼，认识的人再多也没用  爬取动态页面静态页面的内容始终不变，爬取相对容易，但在现实中，日前绝大多数网站的页面都是动态页面。动态页面中的部分内容是浏览器运行页面中的 JavaScript 脚本动态生成的，爬取相对困难。先来看一个简单的动态页面的例子，在浏览器中打开 Quotes"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/quotes.jpg"><meta property="og:image" content="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jsjsjs.jpg"><meta property="og:image" content="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jdd1.jpg"><meta property="og:image" content="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jdd2.jpg"><meta property="og:image" content="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jdd3.jpg"><meta property="og:image" content="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jdd4.jpg"><meta property="og:updated_time" content="2018-04-06T11:52:31.263Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="精通 Scrapy 网络爬虫（三）"><meta name="twitter:description" content="自己不牛逼，认识的人再多也没用  爬取动态页面静态页面的内容始终不变，爬取相对容易，但在现实中，日前绝大多数网站的页面都是动态页面。动态页面中的部分内容是浏览器运行页面中的 JavaScript 脚本动态生成的，爬取相对困难。先来看一个简单的动态页面的例子，在浏览器中打开 Quotes"><meta name="twitter:image" content="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/quotes.jpg"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"right",display:"post",offset:12,offset_float:0,b2t:!1,scrollpercent:!1},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://blog.dongfei.xin/2018-04-01/精通 Scrapy 网络爬虫（三）/"><script type="text/javascript" src="https://dongfei.oss-cn-shanghai.aliyuncs.com/high/high-animation.js"></script><script type="text/javascript" src="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/blog.dongfei.xin.js"></script><title>精通 Scrapy 网络爬虫（三） | 那小子真帅</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><script>!function(e,a,t,n,g,c,o){e.GoogleAnalyticsObject=g,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),o=a.getElementsByTagName(t)[0],c.async=1,c.src="https://www.google-analytics.com/analytics.js",o.parentNode.insertBefore(c,o)}(window,document,"script",0,"ga"),ga("create","100009466-1","auto"),ga("send","pageview")</script><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?8feab02e675ff80af4ab58058d0fcd46";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container sidebar-position-right page-post-detail"><div class="headband"></div><a href="https://github.com/GFigure"><img style="position:absolute;top:0;left:0;border:0" src="https://dongfei.oss-cn-shanghai.aliyuncs.com/forkme_left_orange_ff7600.png" alt="Fork me on GitHub"></a><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">那小子真帅</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">码农，程序猿，技术控</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-search"><a title="小high一下~" style="color:red" rel="alternate" class="mw-harlem_shake_slow wobble shake" href="javascript:shake()"><i class="fa fa-music"></i> &nbsp;&nbsp;High</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocapitalize="off" autocomplete="off" autocorrect="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://blog.dongfei.xin/2018-04-01/精通 Scrapy 网络爬虫（三）/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="那小子真帅"><meta itemprop="description" content=""><meta itemprop="image" content="http://oqiflua2i.bkt.clouddn.com/%E5%9B%BE%E7%89%878.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="那小子真帅"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">精通 Scrapy 网络爬虫（三）</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-01T19:26:21+08:00">2018-04-01 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a class="cloud-tie-join-count" href="/2018-04-01/精通 Scrapy 网络爬虫（三）/#comments" itemprop="discussionUrl"><span class="post-comments-count join-count" itemprop="commentCount"></span> </a></span><span id="/2018-04-01/精通 Scrapy 网络爬虫（三）/" class="leancloud_visitors" data-flag-title="精通 Scrapy 网络爬虫（三）"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数 </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><blockquote class="blockquote-center">自己不牛逼，认识的人再多也没用</blockquote><h5 id="爬取动态页面"><a href="#爬取动态页面" class="headerlink" title="爬取动态页面"></a>爬取动态页面</h5><p>静态页面的内容始终不变，爬取相对容易，但在现实中，日前绝大多数网站的页面都是动态页面。动态页面中的部分内容是浏览器运行页面中的 JavaScript 脚本动态生成的，爬取相对困难。<br>先来看一个简单的动态页面的例子，在浏览器中打开 <a href="http://quotes.toscrape.com/js/" target="_blank" rel="noopener">Quotes</a></p><p><img src="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/quotes.jpg" alt="quotes"></p><a id="more"></a><p>页面中有 10 条名人名言，每一条都包含在一个 <code>&lt;div class=&quot;quto&quot;&gt;</code>元素中。现在，我们在 scrapy shell 环境下尝试爬取页面中的名人名言：<br></p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; scrapy shell http:<span class="comment">//quotes.toscrape.com/js/</span></span><br><span class="line">..................</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'div.quote'</span>)</span><br><span class="line">[]</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><p></p><p>从结果看出。爬取失败了，在页面中没有找到任何包含名人名言的<code>&lt;div class=&quot;quto&quot;&gt;</code>元素，这些<code>&lt;div class=&quot;quto&quot;&gt;</code>就是动态内容，从服务器下载的页面中并不包含它们。浏览器执行了页面中的一段 JavasScipt 代码后，它们才被显示出来。查看源码：<br><img src="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jsjsjs.jpg" alt="jsjsjs.jpg"></p><p>上面是动态网页中最简单的一个例子，数据被硬编码于 JavaScript 代码中，实际中更常见的是 JavaScript 通过 HTTP 请求跟网站动态交互获取数据（AJAX），然后使用数据更新 HTML 页面。爬取此类动态网页需要先执行页面中的 JavaScript 代码渲染页面，再进行爬取。下面介绍使用 JavaScript 渲染引擎渲染页面。</p><h5 id="Splash-渲染引擎"><a href="#Splash-渲染引擎" class="headerlink" title="Splash 渲染引擎"></a>Splash 渲染引擎</h5><p>Splash 是 Scrapy 官方推荐的 JavaScript 渲染引擎，它是使用 Webkit 开发的轻量级无界面浏览器，提供基于 HTTP 接口的 JavaScript 渲染服务，支持以下功能:</p><ul><li>为用户返回经过渲染的 HTML 页面或页面截图。</li><li>并发渲染多个页面。</li><li>关闭图片加载，加速渲染。</li><li>在页面中执行用户自定义的 JavaScript 代码。</li><li>执行用户自定义的渲染脚本（lua），功能类似于 PhantomJS。</li></ul><p><a href="https://github.com/scrapy-plugins/scrapy-splash#installation" target="_blank" rel="noopener">项目链接</a></p><p><a href="http://splash.readthedocs.io/en/latest/scripting-tutorial.html" target="_blank" rel="noopener">API 文档</a></p><p>安装 Splash，需要依赖容器 Docker</p><p>Linux 下安装 Docker 和 Splash ：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-<span class="builtin-name">get</span> install docker</span><br><span class="line">sudo docker pull scrapinghub/splash</span><br></pre></td></tr></table></figure><p></p><p>Windows 下安装参考：</p><ul><li><a href="https://blog.csdn.net/sanyuedexuanlv/article/details/78759743" target="_blank" rel="noopener">安裝 Docker for Windows</a></li><li><a href="https://www.cnblogs.com/zhxshseu/p/5970a5a763c8fe2b01cd2eb63a8622b2.html" target="_blank" rel="noopener">Docker 使用阿里云docker镜像加速</a></li><li><a href="https://www.cnblogs.com/my8100/p/splash_install.html" target="_blank" rel="noopener">Scrapy相关：Splash 安装 A javascript rendering service 渲染</a></li></ul><p>安装完成后，在本机的 8050 和 8051 端口开启 Splash 服务:</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\<span class="number">29485</span></span><br><span class="line">$ docker run -p <span class="number">8050:8050</span> -p <span class="number">8051:8051</span> scrapinghub/splash</span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38:30+0000</span> [-] Log opened.</span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38:30.228904</span> [-] Splash version: <span class="number">3</span>.<span class="number">2</span></span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38:30.246529</span> [-] Qt <span class="number">5</span>.<span class="number">9</span>.<span class="number">1</span>, PyQt <span class="number">5</span>.<span class="number">9</span>, WebKit <span class="number">602</span>.<span class="number">1</span>, sip <span class="number">4</span>.<span class="number">19</span>.<span class="number">3</span>, Twisted <span class="number">16</span>.<span class="number">1</span>.<span class="number">1</span>, Lua <span class="number">5</span>.<span class="number">2</span></span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38:30.248380</span> [-] Python <span class="number">3</span>.<span class="number">5</span>.<span class="number">2</span> (default, Nov <span class="number">23</span> <span class="number">2017</span>, <span class="number">16</span>:<span class="number">37</span>:<span class="number">01</span>) [GCC <span class="number">5</span>.<span class="number">4</span>.<span class="number">0 20160609</span>]</span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38:30.249581</span> [-] Open files limit: <span class="number">1048576</span></span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38:30.249750</span> [-] Can't bump open files limit</span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38</span>:<span class="number">30.373421</span> [-] Xvfb is started: ['Xvfb', ':<span class="number">177507167</span>', '-screen', '<span class="number">0</span>', '<span class="number">1024</span>x768x24', '-nolisten', 'tcp']</span><br><span class="line">QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'</span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38</span>:<span class="number">30.757496</span> [-] proxy profiles support is enabled, proxy profiles path: /etc/splash/proxy-profiles</span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38</span>:<span class="number">31.028505</span> [-] verbosity=<span class="number">1</span></span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38</span>:<span class="number">31.028650</span> [-] slots=<span class="number">50</span></span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38</span>:<span class="number">31.028836</span> [-] argument_cache_max_entries=<span class="number">500</span></span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38</span>:<span class="number">31.030539</span> [-] Web UI: enabled, Lua: enabled (sandbox: enabled)</span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38</span>:<span class="number">31.030702</span> [-] Server listening on <span class="number">0.0.0.0</span>:<span class="number">8050</span></span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38:31.032203</span> [-] Site starting on <span class="number">8050</span></span><br><span class="line"><span class="number">2018-04-02</span> <span class="number">08</span>:<span class="number">38</span>:<span class="number">31.032426</span> [-] Starting factory &lt;twisted.web.server.Site object at <span class="number">0</span>x7f<span class="number">4d140d57f0</span>&gt;</span><br></pre></td></tr></table></figure><p>Splash 功能丰富，包含多个服务端点，这里只介绍其中两个最常用的端点</p><ul><li><p>render.html<br>提供 JavaScript 页面渲染服务。</p></li><li><p>execute<br>执行用户自定义的渲染脚本（lua），利用该端点可在页面中执行 JavaScript 代码</p></li></ul><h6 id="render-html-端点"><a href="#render-html-端点" class="headerlink" title="render.html 端点"></a>render.html 端点</h6><p>JavaScript 页面渲染服务是 Splash 中最基础的服务，调用方式如下：<br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">服务端点             render.html</span><br><span class="line">请求地址             http:<span class="comment">//:locallhost:8050/render.html</span></span><br><span class="line">请求方式             GET / POST</span><br><span class="line">返回类型             html</span><br></pre></td></tr></table></figure><p></p><p>render.html 端点支持的参数如下所示：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">参数              是否必选        类型         描述</span><br><span class="line">url                 必选         string    需要渲染页面的 url</span><br><span class="line">timeout             可选         float    渲染页面超时时间     </span><br><span class="line">proxy               可选         string    代理服务器地址 </span><br><span class="line">wait                可选         float     等待页面渲染的时间</span><br><span class="line">images              可选         integer   是否下载图片，默认为 1</span><br><span class="line">js_source           可选         string    用户自定义的 JavaScript 代码的，在页面渲染前执行</span><br></pre></td></tr></table></figure><p></p><p>这里仅列出部分常用参数，详细内容参见官方文档。<br>下面是使用 requests 库调用 render.html 端点服务对页面 <code>http://quotes.toscrape.com/js/</code> 进行渲染的示例代码。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import requests</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">from</span> scrapy.selector import Selector</span><br><span class="line">&gt;&gt;&gt; splash_url = <span class="string">"http://localhost:8050/render.html"</span></span><br><span class="line">&gt;&gt;&gt; args = &#123;'url':<span class="string">"http://quotes.toscrape.com/js/"</span>, '<span class="keyword">timeout</span>':<span class="number">5</span>, 'image':<span class="number">0</span>&#125;</span><br><span class="line">&gt;&gt;&gt; response = requests.<span class="keyword">get</span>(splash_url,params=args)</span><br><span class="line">&gt;&gt;&gt; sel = Selector(response)</span><br><span class="line">&gt;&gt;&gt; sel.css('<span class="keyword">div</span>.<span class="literal">quote</span> span.<span class="built_in">text</span>::<span class="built_in">text</span>').extract()</span><br><span class="line">['“The world <span class="keyword">as</span> we have created <span class="keyword">it</span> <span class="keyword">is</span> a process <span class="keyword">of</span> our thinking. It cannot be changed <span class="keyword">without</span> changing our thinking.”', '“It <span class="keyword">is</span> our c</span><br><span class="line">hoices, Harry, <span class="keyword">that</span> show what we truly are, far more than our abilities.”', '“There are only two ways <span class="keyword">to</span> live your life. One <span class="keyword">is</span> <span class="keyword">as</span> tho</span><br><span class="line">ugh nothing <span class="keyword">is</span> a miracle. The other <span class="keyword">is</span> <span class="keyword">as</span> though everything <span class="keyword">is</span> a miracle.”', '“The person, be <span class="keyword">it</span> gentleman <span class="keyword">or</span> lady, who has <span class="keyword">not</span> pleasu</span><br><span class="line">re <span class="keyword">in</span> a good novel, must be intolerably stupid.”', <span class="string">"“Imperfection is beauty, madness is genius and it's better to be absolutely ridicu</span></span><br><span class="line"><span class="string">lous than absolutely boring.”"</span>, '“Try <span class="keyword">not</span> <span class="keyword">to</span> become a man <span class="keyword">of</span> success. Rather become a man <span class="keyword">of</span> value.”', '“It <span class="keyword">is</span> better <span class="keyword">to</span> be hated fo</span><br><span class="line">r what you are than <span class="keyword">to</span> be loved <span class="keyword">for</span> what you are <span class="keyword">not</span>.”', <span class="string">"“I have not failed. I've just found 10,000 ways that won't work.”"</span>, <span class="string">"“A wo</span></span><br><span class="line"><span class="string">man is like a tea bag; you never know how strong it is until it's in hot water.”"</span>, '“A <span class="built_in">day</span> <span class="keyword">without</span> sunshine <span class="keyword">is</span> like, you know, night.</span><br><span class="line">”']</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><p>在上述代码中，依据文档中的描述设置参数 url、timeout、images，然后发送 HTTP 请求服务接口地址。从运行结果看出，页面渲染成功，我们爬取到了页面中的 10 条名人名言。</p><h6 id="execute-端点"><a href="#execute-端点" class="headerlink" title="execute 端点"></a>execute 端点</h6><p>在爬取某些页面时，我们想在页面中执行一些用户自定义的 JavaScript 代码，例如用 JavaScript 模拟点击页面中的按钮，或调用页面中的 JavaScript 函数与服务器交互。利用 Splash 的 execute 端点提供的服务可以实现这样的功能。</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">服务端点            execute</span><br><span class="line">请求地址            http://localhost:8050/execute</span><br><span class="line">请求方式            POST</span><br><span class="line">返回类型            自定义</span><br></pre></td></tr></table></figure><p>execute 端点支持的参数如下：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">参数          必选/可选       类型         描述</span><br><span class="line">lua_source      必选          string      用户自定义的 lua 脚本</span><br><span class="line">timeout         可选          float       渲染页面超时时间</span><br><span class="line">proxy           可选          string      代理服务器地址</span><br></pre></td></tr></table></figure><p></p><p>我们可以将 execute 端点的服务看作一个可用 lua 语言编程的浏览器，功能类似于 PhantomJS。使用时需传递一个用户自定义的 lua 脚本给 Splash,该 lua 脚本中包含用户<br>想要模拟的浏览器行为，例如:</p><ul><li>打开某 url 地址的页面</li><li>等待页面加载及渲染</li><li>执行 JavaScript 代码</li><li>获取 HTTP 响应头部</li><li>获取 Cookie</li></ul><p>下面使用 requests 库调用 execute 端点服务的示例代码：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> json</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lua_script = <span class="string">'''</span></span><br><span class="line"><span class="string"><span class="meta">... </span>function main(splash):</span></span><br><span class="line"><span class="string"><span class="meta">... </span>    splash:go("http://blog.dongfei.xin/")</span></span><br><span class="line"><span class="string"><span class="meta">... </span>    spalsh:wait(0.5)</span></span><br><span class="line"><span class="string"><span class="meta">... </span>    local title = splash:evaljs("document.title")</span></span><br><span class="line"><span class="string"><span class="meta">... </span>    return &#123;title = title&#125;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>end</span></span><br><span class="line"><span class="string"><span class="meta">... </span>'''</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>splash_url = <span class="string">'http://localhost:8050/execute'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = json.dumps(&#123;<span class="string">'lua_source'</span>: lua_script&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>headers = &#123;<span class="string">'content-type'</span>:<span class="string">'application/json'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>response= requests.post(splash_url,headers=headers,data=data)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>response.content</span><br><span class="line"><span class="string">b'&#123;"title":"那小子真帅"&#125;'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>response.json()</span><br><span class="line">&#123;<span class="string">'title'</span>:<span class="string">'那小子真帅'</span>&#125;</span><br></pre></td></tr></table></figure><p></p><p>用户自定义的 lua 脚本中必须包含一个 main 函数作为程序入口，main 函数被调用时会传入一个 splash 对象（lua 中的对象），用户可以调用该对象上的方法操纵 Splash 。例如，在上面的例子中，先调用 go 方法打开某页面，再调用 wait 方法等待页面渲染，然后调用 evaljs 方法执行一个 JavaScript 表达式，并将结果转化为相应的 lua 对象，最终 Splash 根据 main 函数的返回值构造 HTTP 响应返回给用户，main 函数的返回值可以是字符串，也可以是 lua 中的表（类似 Python 字典）表会被编码成 json 串。</p><p>splash 对象常用的属性和方法。</p><ul><li>splash.args 属性</li></ul><p>用户传入参数的表，通过该属性可以访问用户传入的参数，如 splash.args.url、<br>splash.args.wait。</p><ul><li>splash.js_enabled 属性</li></ul><p>用于开启/禁止 JavaScript 渲染，默认为 true。</p><ul><li>splash.images_enabled 属性</li></ul><p>用于开启/禁止图片加载，默认为 true。</p><ul><li>splash:go 方法</li></ul><p>splash:go{url,baseurl=nil,headers=nil,http_method=”GET”,body=nil,formdata=nil}类似于在浏览器中打开某 url 地址的页面，页面所需资源会被加载，并进行 JavaScript 渲染，可以通过参数指定 HTTP 请求头部、请求方法、表单数据等。</p><ul><li>splash:wait 方法</li></ul><p>splash:wait{time,cancel_on_redirect=false,cancel_on_error=true} 等待页面渲染，time 参数为等待的秒数。</p><ul><li>splash:evaljs 方法</li></ul><p>splash:evaljs(snippet)<br>在当前页面下，执行一段 JavaScript 代码，并返回最后一句表达式的值。</p><ul><li>splash:runjs 方法</li></ul><p>splash:runjs(snippet)<br>在当前页面下，执行一段 JavaScript 代码，与 evaljs 方法相比，该函数只执行 JavaScript 代码，不返回值。</p><ul><li>splash:url 方法</li></ul><p>splash:url()<br>获取当前页面的 url</p><ul><li>splash:html 方法</li></ul><p>splash:html()<br>获取当前页面的 HTML 文本。</p><ul><li>splash:get_cookies 方法</li></ul><p>splash:get_cookies()<br>获取全部 Cookie 信息。</p><h5 id="在-Scrapy-中使用Splash"><a href="#在-Scrapy-中使用Splash" class="headerlink" title="在 Scrapy 中使用Splash"></a>在 Scrapy 中使用Splash</h5><p>在 Scrapy 中调用 Splash 服务，需要安装 scrapy-splash：<code>pip install scrapy-splash</code></p><p>在项目配置文件 setting.py 中对 scrapy-plash 进行配置：<br></p><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># Splash服务器地址 </span></span><br><span class="line">SPLASH_URL = <span class="string">'http://localhost:8050/'</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># 开启 Splash 的两个下载中间件并调整 HttpCompressionMiddleware 的次序</span></span><br><span class="line"></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashCookiesMiddleware'</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">'scrapy_splash.SplashMiddleware'</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta"># 设置去重过滤器</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">'scrapy_splash.SplashAwareDupeFilter'</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># 用来支持 cache_args （可选）</span></span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">'scrapy_splash.SplashDeduplicateArgsMiddleware'</span>: <span class="number">100</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>使用 scrapy_splash 调用 Splash 服务非常筒单，scrapy_splash 中定义了一个 SplashRequest 类，用户只需使用 scrapy_splash.SplashRequest （替代scrapy .Request）提交请求即可。下面是 SplashRequest 构造器方法中的一些常用参数。</p><ul><li>url</li></ul><p>与 scrapy.Request 中的 url 相同，也就是待爬取页面的 url（注意，不是Splash 服务器地址）</p><ul><li>headers</li></ul><p>与 scrapy.Request 中的 headers 相同。</p><ul><li>cookies</li></ul><p>与 scrapy.Request 中的 cookies 相同。</p><ul><li>args</li></ul><p>传递给 Splash 的参数（除 url 以外），如 wait、timeout、images、js_source 等。</p><ul><li>cache_args</li></ul><p>如果 args 中的某些参数每次调用都重复传递并且数据量较大（例如一段 JavaScript 代码），此时可以把该参数名填入 cache_args 列表中，让 Splash 服务器缓存该参数，如 SplashRequest(url,args={‘js_source’: js,’wait’: 0.5},cache_args=[‘js_source’])。</p><ul><li>endpoint</li></ul><p>Splash 服务端点，默认为 <code>render.html</code>，即 JavaScript 页面渲染服务，该参数可以设置为 <code>render.json</code>、<code>render.har</code>、<code>render.png</code>、<code>render.jpeg</code>、<code>execute</code>等，更多服务端点可以查阅文档。</p><ul><li>splash_url</li></ul><p>Splash 服务器地址，默认为 None，即使用配置文件中 SPLASH_URL 的地址。</p><h5 id="项目实战-爬取-toscrape-中的名人名言"><a href="#项目实战-爬取-toscrape-中的名人名言" class="headerlink" title="项目实战: 爬取 toscrape 中的名人名言"></a>项目实战: 爬取 toscrape 中的名人名言</h5><ul><li>项目需求</li></ul><p>爬取网站 <a href="http://quotes.toscrape.com/js/" target="_blank" rel="noopener">http://quotes.toscrape.com/js/</a> 中的名人名言信息。</p><ul><li>编码实现</li></ul><p>项目目录下使用 scrapy genspider 命令创建 Spider：<br></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">scrapy</span> <span class="selector-tag">genspider</span> <span class="selector-tag">quotes</span> <span class="selector-tag">quotes</span><span class="selector-class">.toscrape</span><span class="selector-class">.com</span></span><br></pre></td></tr></table></figure><p></p><p>这个案例中。我们只使用 Splash 的 render.html 端点渲染页面，再进行爬取即<br>可实现 QuotesSpider，代码如下：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line">__author_<span class="number">_</span> = <span class="string">"東飛"</span></span><br><span class="line">__date_<span class="number">_</span> = <span class="string">"2017-11-29"</span></span><br><span class="line">import scrapy</span><br><span class="line">from scrapy_splash import SplashRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span>(<span class="title">scrapy</span>.<span class="title">Spider</span>):</span></span><br><span class="line">    name = <span class="string">'quotes'</span></span><br><span class="line">    allowed_domains = [<span class="string">'quotes.toscrape.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    custom_settings = &#123;</span><br><span class="line">        <span class="comment"># Splash服务器地址</span></span><br><span class="line">        <span class="string">'SPLASH_URL'</span>: <span class="string">'http://localhost:8050/'</span>,</span><br><span class="line">        <span class="comment"># 开启 Splash 的两个下载中间件并调整 HttpCompressionMiddleware 的次序</span></span><br><span class="line">        <span class="string">'DOWNLOADER_MIDDLEWARES'</span>: &#123;</span><br><span class="line">            <span class="string">'scrapy_splash.SplashCookiesMiddleware'</span>: <span class="number">723</span>,</span><br><span class="line">            <span class="string">'scrapy_splash.SplashMiddleware'</span>: <span class="number">725</span>,</span><br><span class="line">            <span class="string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: <span class="number">810</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment"># 设置去重过滤器</span></span><br><span class="line">        <span class="string">'DUPEFILTER_CLASS'</span>: <span class="string">'scrapy_splash.SplashAwareDupeFilter'</span>,</span><br><span class="line">        <span class="comment"># 用来支持 cache_args （可选）</span></span><br><span class="line">        <span class="string">'SPIDER_MIDDLEWARES'</span>: &#123;</span><br><span class="line">            <span class="string">'scrapy_splash.SplashDeduplicateArgsMiddleware'</span>: <span class="number">100</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> <span class="keyword">self</span>.<span class="symbol">start_urls:</span></span><br><span class="line">            <span class="keyword">yield</span> SplashRequest(url, args=&#123;<span class="string">'images'</span>: <span class="number">0</span>, <span class="string">'timeout'</span>: <span class="number">3</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> sel <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>)<span class="symbol">:</span></span><br><span class="line">            quote = <span class="keyword">self</span>.css(<span class="string">'span.text::text'</span>).extract_first()</span><br><span class="line">            author = <span class="keyword">self</span>.css(<span class="string">'small.author::text'</span>).extract_first()</span><br><span class="line">            <span class="keyword">yield</span> &#123;<span class="string">'quote'</span>: quote, <span class="string">'author'</span>: author&#125;</span><br><span class="line"></span><br><span class="line">        href = response.css(<span class="string">'li.next&gt;a::attr(href)'</span>).extract_first()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="symbol">href:</span></span><br><span class="line">            url = response.urljoin(href)</span><br><span class="line">            <span class="keyword">yield</span> SplashRequest(url, args=&#123;<span class="string">'images'</span>: <span class="number">0</span>, <span class="string">'timeout'</span>: <span class="number">3</span>&#125;)</span><br></pre></td></tr></table></figure><p>上述代码中。使用 SplashRequest 提交请求，SplashRequest 的构造器中无须传递<br>endpoint 参数，因为该参数默认值便是 <code>render.html</code> 。使用 args 参数禁止 Splash 加载图片，并设置渲染超时时间。<br>运行爬虫，观察结果：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> scrapy crawl quotes -o .\data\quotes.csv</span><br><span class="line"></span><br><span class="line"> F:\VirtualEnv\jobboleArticle\ArticleSpider\ArticleSpider</span><br><span class="line">(jobboleArticle) $ cat -n .\data\quotes.csv</span><br><span class="line">     <span class="number">1</span>  <span class="literal">quote</span>,author</span><br><span class="line">     <span class="number">2</span>  “The world <span class="keyword">as</span> we have created <span class="keyword">it</span> <span class="keyword">is</span> a process <span class="keyword">of</span> our thinking. It cannot be changed <span class="keyword">without</span> changing our thinking.”,Albert Ein</span><br><span class="line">stein</span><br><span class="line">     <span class="number">3</span>  <span class="string">"“It is our choices, Harry, that show what we truly are, far more than our abilities.”"</span>,J.K. Rowling</span><br><span class="line">     <span class="number">4</span>  “There are only two ways <span class="keyword">to</span> live your life. One <span class="keyword">is</span> <span class="keyword">as</span> though nothing <span class="keyword">is</span> a miracle. The other <span class="keyword">is</span> <span class="keyword">as</span> though everything <span class="keyword">is</span> a mirac le.”,Albert Einstein</span><br></pre></td></tr></table></figure><h5 id="项目实战-爬取京东商城中的书籍信息"><a href="#项目实战-爬取京东商城中的书籍信息" class="headerlink" title="项目实战: 爬取京东商城中的书籍信息"></a>项目实战: 爬取京东商城中的书籍信息</h5><ul><li>项目需求</li></ul><p>爬取京东商城中所有 Python 书籍的名字和价格信息。</p><ul><li>页面分析</li></ul><p>在<a href="http://www.jd.com" target="_blank" rel="noopener">京东网站</a>的书籍分类下搜索 Python 关键字得到的页面<br><img src="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jdd1.jpg" alt=""></p><p>结果有很多页，在每个书籍列表页面中可以数有 60 本书但在 scrapy shell<br>中爬取该页面时遇到了问题，仅在页面中找到了 30 本书，少了30本，代码如下:<br></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">F:</span>\VirtualEnv\jobboleArticle\ArticleSpider\ArticleSpider</span><br><span class="line">(jobboleArticle) $ scrapy shell</span><br><span class="line"></span><br><span class="line">.............</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; url = <span class="string">"https://search.jd.com/Search?keyword=python&amp;enc=utf-8&amp;wq=python"</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; fetch(url)</span><br><span class="line"><span class="number">2018</span>-<span class="number">04</span>-<span class="number">06</span> <span class="number">16</span><span class="symbol">:</span><span class="number">52</span><span class="symbol">:</span><span class="number">03</span> [scrapy.core.engine] <span class="symbol">INFO:</span> Spider opened</span><br><span class="line"><span class="number">2018</span>-<span class="number">04</span>-<span class="number">06</span> <span class="number">16</span><span class="symbol">:</span><span class="number">52</span><span class="symbol">:</span><span class="number">04</span> [scrapy.core.engine] <span class="symbol">DEBUG:</span> Crawled (<span class="number">200</span>) &lt;GET <span class="symbol">https:</span>/<span class="regexp">/search.jd.com/</span>Search?keyword=python&amp;enc=utf-<span class="number">8</span>&amp;wq=python&gt; (<span class="symbol">referer:</span> None)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; len(response.css(<span class="string">'ul.gl-warp&gt;li'</span>))</span><br><span class="line"><span class="number">30</span></span><br></pre></td></tr></table></figure><p></p><p>原来页面中的 60 本书不是同时加载的，开始只有 30 本书，当我们使用鼠标滚轮滚动到页面下方某位置时，后 30 本书才由 JavaScript 脚本加载，通过实验可以验证这个说法，实验绝视如下：</p><p>（1） 页面刚加载时，在 Chrome 开发者工具的 console 中用 jQuery 代码查看当前<br>有多少本书，此时为 30。</p><p>（2） 之后滚动鼠标滚轮到某一位置时，可以看到 JavaScript 发送 HTTP 请求和服务<br>器交互（XHR）。</p><p>（3） 然用 jQuery 代码查看当前有多少本书，已经变成了 60 ，如图所示，</p><p><img src="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jdd2.jpg" alt=""></p><p>既然如此，爬取这个页面时，可以先执行一段 JavaScript 代码，将滚动条拖到页面下方某位置，触发加载后 30 本书的事件，在开发者工具的 console 中进行实验，用 document.getElementsByXXX 方法随意选中页面下方的某元素，比如<code>下一页</code> 按钮所在的<code>&lt;div&gt;</code>元素，然后在该元素对象上调用 scrollIntoView(true) 完成拖曳动作，此时查看书籍数量，变成了 60 。如图：</p><p><img src="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jdd3.jpg" alt=""></p><p>爬取一个页面的问题解决了，再宋研究如何从页面中找到下一页的 url 地址。下一页链接的 href 属性并不是一个 url，而在其 onclick 属性中包含了一条 JavaScript 代码，单击<code>下一页</code>按钮时会调函数<code>SEARCH.page(n,true)</code>。虽然<br>可以用 Splash 执行函数来跳转到下一页，但还是很麻烦，经观察发现，每个页面 url 的差异仅在于 page 参数不同，第一页<code>page=1</code>、第二页 <code>page=3</code>、第三页 <code>page=5</code> …… 以 2 递增，并且页面中还包含商品总数信息。因此，我们可以推算出所有页面的 url 。</p><p><img src="https://dongfei.oss-cn-shanghai.aliyuncs.com/blog/jdd4.jpg" alt=""></p><ul><li>编码实现</li></ul><p>项目目录下使用 scrapy genspider 命令创建 Spider：<br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider jd_book search<span class="selector-class">.jd</span><span class="selector-class">.com</span></span><br></pre></td></tr></table></figure><p></p><p>经上述分析，在爬取每一个书籍列表页面时都需要执行一段 JavaScript 代码，以让全部书籍加载，因此选用 Splash 的 execute 端点渲染页面，再进行爬取即<br>可实现 JdBookSpider，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line">__author__ = <span class="string">"東飛"</span></span><br><span class="line">__date__ = <span class="string">"2017-11-29"</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest</span><br><span class="line"></span><br><span class="line">lua_script = <span class="string">'''</span></span><br><span class="line"><span class="string">function main(splash)</span></span><br><span class="line"><span class="string">    splash:go(splash.args.url)</span></span><br><span class="line"><span class="string">    splash:wait(2)</span></span><br><span class="line"><span class="string">    splash:runjs("document.getElementsByClassName('page')[0].scrollIntoView(true)")</span></span><br><span class="line"><span class="string">    splash:wait(2)</span></span><br><span class="line"><span class="string">    return splash:html()</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JdBookSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'jd_book'</span></span><br><span class="line">    allowed_domains = [<span class="string">'search.jd.com'</span>]</span><br><span class="line">    base_url = <span class="string">'https://search.jd.com/Search?keyword=python&amp;enc=utf-8&amp;book=y&amp;wq=python'</span></span><br><span class="line"></span><br><span class="line">    custom_settings = &#123;</span><br><span class="line">        <span class="comment"># Splash服务器地址</span></span><br><span class="line">        <span class="string">'SPLASH_URL'</span>: <span class="string">'http://localhost:8050/'</span>,</span><br><span class="line">        <span class="comment"># 开启 Splash 的两个下载中间件并调整 HttpCompressionMiddleware 的次序</span></span><br><span class="line">        <span class="string">'DOWNLOADER_MIDDLEWARES'</span>: &#123;</span><br><span class="line">            <span class="string">'ArticleSpider.middlewares.RandomUserAgentMiddleware'</span>: <span class="number">722</span>,</span><br><span class="line">            <span class="string">'scrapy_splash.SplashCookiesMiddleware'</span>: <span class="number">723</span>,</span><br><span class="line">            <span class="string">'scrapy_splash.SplashMiddleware'</span>: <span class="number">725</span>,</span><br><span class="line">            <span class="string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: <span class="number">810</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment"># 设置去重过滤器</span></span><br><span class="line">        <span class="string">'DUPEFILTER_CLASS'</span>: <span class="string">'scrapy_splash.SplashAwareDupeFilter'</span>,</span><br><span class="line">        <span class="comment"># 用来支持 cache_args （可选）</span></span><br><span class="line">        <span class="string">'SPIDER_MIDDLEWARES'</span>: &#123;</span><br><span class="line">            <span class="string">'scrapy_splash.SplashDeduplicateArgsMiddleware'</span>: <span class="number">100</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment"># 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36',</span></span><br><span class="line">        <span class="comment"># 'HTTPERROR_ALLOWED_CODES': [400],</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 请求第一页，无须 js 渲染</span></span><br><span class="line">        <span class="keyword">yield</span> Request(self.base_url, callback=self.parse_urls, dont_filter=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># 获取一个页面中每本书的名字和价格</span></span><br><span class="line">        <span class="keyword">for</span> sel <span class="keyword">in</span> response.css(<span class="string">'ul.gl-warp.clearfix &gt; li.gl-item'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'name'</span>: sel.css(<span class="string">'div.p-name'</span>).xpath(<span class="string">'string(.//em)'</span>).extract_first(),</span><br><span class="line">                <span class="string">'price'</span>: sel.css(<span class="string">'div.p-price i::text'</span>).extract_first(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_urls</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># 获取商品总数，计算出总页数</span></span><br><span class="line">        total = int(response.css(<span class="string">'span#J_resCount::text'</span>).re_first(<span class="string">'\d+'</span>))</span><br><span class="line">        pageNum = total // <span class="number">60</span> + (<span class="number">1</span> <span class="keyword">if</span> total % <span class="number">60</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构造每页的 url，向 Splash 的 execute 端点发送请求</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(pageNum):</span><br><span class="line">            url = <span class="string">'%s&amp;page=%s'</span> % (self.base_url, <span class="number">2</span> * i + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">yield</span> SplashRequest(</span><br><span class="line">                    url,</span><br><span class="line">                    endpoint=<span class="string">'execute'</span>,</span><br><span class="line">                    args=&#123;<span class="string">'lua_source'</span>: lua_script&#125;,</span><br><span class="line">                    cache_args=[<span class="string">'lua_source'</span>]</span><br><span class="line">            )</span><br></pre></td></tr></table></figure><p>解释上述代码如下：</p><ul><li>start_requests 方法</li></ul><p>start_requests 提交对第一个页面的请求，这个页面不需要渲染，因为我们只想从中获取页面总数，使用 scrapy.Request 提交请求，并指定 parse_urls 作为解析函数。</p><ul><li>parse_urls 方法</li></ul><p>从第一个页面中提取商品总数，用其计算页面总数，之后按照前面分析出的页面 url 规律构造每一个页面的 url 。这些页面都是需要渲染的，使用 SplashRequest 提交请求，除了渲染页面以外，还需要执行一段 JavaScript 代码（为了加载后 30 本书），因此使用 Splash 的 execute 端点将 endpoint 参数置为 <code>execute</code> 。通过 args 参数的 lua_source 字段传递我们要执行的 lua 脚本，由于爬取每个页面时都要执行该脚本，因此可以使用 cache_args 参数将该脚本缓存到 Splash 服务器。</p><ul><li>parse 方法</li></ul><p>一个页面中提取 60 本书的名字和价格信息。</p><ul><li>lua_script</li></ul><p>自定义的 lua 脚 本，其中的逻辑很简单:<br>打开页面 ==》 等待渲染 ==》 执行 js 触发数据加载（后 30 本书） ==》 等待渲染 ==》 返四 html</p><p>编码和配置的完成，运行爬虫：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">jobboleArticle) </span>$ <span class="keyword">scrapy </span>crawl <span class="keyword">jd_book </span>-o .\data\<span class="keyword">books.csv</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">(jobboleArticle) </span>$ cat -n .\data\<span class="keyword">books.csv</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">5928 </span> 包邮 Python Web开发实战+Python Web开发 测试驱动方法  <span class="number">2</span>本,<span class="number">153</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5929</span>  包邮 Python编程导论 <span class="number">2</span>版+ Python <span class="number">3</span>学习笔记  <span class="number">2</span>本 编程程序,<span class="number">118</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5930</span>  包邮数据科学家养成手册+Python大战机器学习:数据科学家的第一个小目标  <span class="number">2</span>本,<span class="number">112</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5931</span>  包邮 Python参考手册（第<span class="number">4</span>版修订版）+Python数据抓取技术与实战  <span class="number">2</span>本,<span class="number">104</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5932</span>  包邮  Python数据处理+Python网络数据采集 <span class="number">2</span>本 python编程入门书籍,<span class="number">115</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5933</span>  包邮 Python网络编程 第<span class="number">3</span>版+Python网络数据采集  <span class="number">2</span>本,<span class="number">103</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5934</span>  包邮Metasploit渗透测试指南（修订版）+Python黑帽子:黑客与渗透测试编程之道,<span class="number">101</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5935</span>  包邮 Python性能分析与优化+Python算法教程  <span class="number">2</span>本,<span class="number">85</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5936</span>  包邮 数据科学实战手册（R+Python）+干净的数据:数据清洗入门与实践 <span class="number">2</span>本,<span class="number">80</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5937</span>  包邮 Web接口开发与自动化测试——基于Python语言+软件自动化测试开发  <span class="number">2</span>本,<span class="number">88</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5938</span>  零起点Python大数据与量化交易 何海群 <span class="number">9787121306594</span>,<span class="number">74</span>.<span class="number">30</span></span><br><span class="line"><span class="number">5939</span>  从Python开始学编程,<span class="number">29</span>.<span class="number">40</span></span><br><span class="line"><span class="number">5940</span>  区域包邮 Python游戏编程入门+Maya Python 游戏与影视编程指南  <span class="number">2</span>本,<span class="number">96</span>.<span class="number">00</span></span><br><span class="line"><span class="number">5941</span>  包邮  Python与机器学习实战+TensorFlow技术解析与实战 <span class="number">2</span>本,<span class="number">112</span>.<span class="number">00</span></span><br></pre></td></tr></table></figure></div><div></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div><button id="rewardButton" disable="enable" onclick='var qr=document.getElementById("QR");"none"===qr.style.display?qr.style.display="block":qr.style.display="none"'><span>赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="http://oqiflua2i.bkt.clouddn.com/微信支付.png" alt="那小子真帅 WeChat Pay"><p>微信打赏</p></div><div id="alipay" style="display:inline-block"><img id="alipay_qr" src="http://oqiflua2i.bkt.clouddn.com/支付宝支付.png" alt="那小子真帅 Alipay"><p>支付宝打赏</p></div></div></div></div><div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Python/" rel="tag"># Python</a> <a href="/tags/Scrapy/" rel="tag"># Scrapy</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018-03-30/精通 Scrapy 网络爬虫（二）/" rel="next" title="精通 Scrapy 网络爬虫（二）"><i class="fa fa-chevron-left"></i> 精通 Scrapy 网络爬虫（二）</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018-04-06/精通-Scrapy-网络爬虫（四）/" rel="prev" title="精通 Scrapy 网络爬虫（四）">精通 Scrapy 网络爬虫（四） <i class="fa fa-chevron-right"></i></a></div></div></footer></article><div class="post-spread"><div class="jiathis_style"><a class="jiathis_button_tsina"></a> <a class="jiathis_button_tqq"></a> <a class="jiathis_button_weixin"></a> <a class="jiathis_button_cqq"></a> <a class="jiathis_button_douban"></a> <a class="jiathis_button_renren"></a> <a class="jiathis_button_qzone"></a> <a class="jiathis_button_kaixin001"></a> <a class="jiathis_button_copy"></a> <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a> <a class="jiathis_counter_style"></a></div><script type="text/javascript">var jiathis_config={hideMore:!1}</script><script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script></div></div></div><div class="comments" id="comments"><div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div><script src="https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js"></script><script>var cloudTieConfig={url:document.location.href,sourceId:"",productKey:"f466c18e6eea4e24bc686a8ae4514dae",target:"cloud-tie-wrapper"},yunManualLoad=!0;Tie.loader("aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s",!0)</script></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview">站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="http://oqiflua2i.bkt.clouddn.com/%E5%9B%BE%E7%89%878.png" alt="那小子真帅"><p class="site-author-name" itemprop="name">那小子真帅</p><p class="site-description motion-element" itemprop="description">有酒有肉有朋友，能贫能笑能干架</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">111</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">32</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">37</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/GFigure" target="_blank" title="GitHub"><i class="fa fa-fw fa-globe"></i> GitHub </a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/geng-dong-fei" target="_blank" title="知乎"><i class="fa fa-fw fa-bandcamp"></i> 知乎 </a></span><span class="links-of-author-item"><a href="http://www.jianshu.com/u/507e68ab9a5a" target="_blank" title="简书"><i class="fa fa-fw fa-book"></i> 简书 </a></span><span class="links-of-author-item"><a href="mailto:iamdongfei@foxmail.com" target="_blank" title="邮箱"><i class="fa fa-fw fa-envelope"></i> 邮箱 </a></span><span class="links-of-author-item"><a href="https://www.facebook.com/profile.php?id=100012742063569" target="_blank" title="Facebook"><i class="fa fa-fw fa-facebook-official"></i> Facebook </a></span><span class="links-of-author-item"><a href="https://plus.google.com/u/0/" target="_blank" title="Google+"><i class="fa fa-fw fa-google-plus-square"></i> Google+ </a></span><span class="links-of-author-item"><a title="嗨一下" style="underline:none;color:red" rel="alternate" class="mw-harlem_shake_slow wobble shake" href="javascript:shake()"><i class="fa fa-music"></i> &nbsp;&nbsp;High</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-globe"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://www.csdn.net/" title="CSDN" target="_blank">CSDN</a></li><li class="links-of-blogroll-item"><a href="https://www.github.com" title="Github" target="_blank">Github</a></li><li class="links-of-blogroll-item"><a href="https://segmentfault.com/" title="Segmentfault" target="_blank">Segmentfault</a></li><li class="links-of-blogroll-item"><a href="https://www.oschina.net/" title="OsChina" target="_blank">OsChina</a></li></ul></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-5"><a class="nav-link" href="#爬取动态页面"><span class="nav-number">1.</span> <span class="nav-text">爬取动态页面</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Splash-渲染引擎"><span class="nav-number">2.</span> <span class="nav-text">Splash 渲染引擎</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#render-html-端点"><span class="nav-number">2.1.</span> <span class="nav-text">render.html 端点</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#execute-端点"><span class="nav-number">2.2.</span> <span class="nav-text">execute 端点</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#在-Scrapy-中使用Splash"><span class="nav-number">3.</span> <span class="nav-text">在 Scrapy 中使用Splash</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#项目实战-爬取-toscrape-中的名人名言"><span class="nav-number">4.</span> <span class="nav-text">项目实战: 爬取 toscrape 中的名人名言</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#项目实战-爬取京东商城中的书籍信息"><span class="nav-number">5.</span> <span class="nav-text">项目实战: 爬取京东商城中的书籍信息</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">那小子真帅</span></div><div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div><div class="theme-info">主题 - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/three/three.min.js"></script><script type="text/javascript" src="/lib/three/three-waves.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script><script type="text/javascript">var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path;function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".popup").toggle()}var searchFunc=function(e,c,s){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var t=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),a=document.getElementById(c),r=document.getElementById(s);a.addEventListener("input",function(){var u=0,d='<ul class="search-result-list">',f=this.value.trim().toLowerCase().split(/[\s\-]+/);r.innerHTML="",1<this.value.trim().length&&t.forEach(function(e){var a=!1,r=e.title.trim().toLowerCase(),c=e.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),t=decodeURIComponent(e.url),s=-1,o=-1,n=-1;if(""!=r&&f.forEach(function(e,t){s=r.indexOf(e),o=c.indexOf(e),(0<=s||0<=o)&&(a=!0,0==t&&(n=o))}),a){u+=1,d+="<li><a href='"+t+"' class='search-result-title'>"+r+"</a>";var i=e.content.trim().replace(/<[^>]+>/g,"");if(0<=n){var l=n-20,p=n+80;l<0&&(l=0),0==l&&(p=50),p>i.length&&(p=i.length);var h=i.substring(l,p);f.forEach(function(e){var t=new RegExp(e,"gi");h=h.replace(t,'<b class="search-keyword">'+e+"</b>")}),d+='<p class="search-result">'+h+"...</p>"}d+="</li>"}}),d+="</ul>",0==u&&(d='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==f&&(d='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),r.innerHTML=d}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("cmVXt6URwS0fSRTsfStnNLTi-gzGzoHsz","O8mac9LovG7JWC2ucYMbj7pM")</script><script>function showTime(e){var t=new AV.Query(e),c=[],u=$(".leancloud_visitors");u.each(function(){c.push($(this).attr("id").trim())}),t.containedIn("url",c),t.find().done(function(e){var t=".leancloud-visitors-count";if(0!==e.length){for(var n=0;n<e.length;n++){var o=e[n],i=o.get("url"),s=o.get("time"),r=document.getElementById(i);$(r).find(t).text(s)}for(n=0;n<c.length;n++){i=c[n],r=document.getElementById(i);var l=$(r).find(t);""==l.text()&&l.text(0)}}else u.find(t).text(0)}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(i){var e=$(".leancloud_visitors"),s=e.attr("id").trim(),r=e.attr("data-flag-title").trim(),t=new AV.Query(i);t.equalTo("url",s),t.find({success:function(e){if(0<e.length){var t=e[0];t.fetchWhenSave(!0),t.increment("time"),t.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var n=new i,o=new AV.ACL;o.setPublicReadAccess(!0),o.setPublicWriteAccess(!0),n.setACL(o),n.set("title",r),n.set("url",s),n.set("time",1),n.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):1<$(".post-title-link").length&&showTime(e)})</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/javascript" src="/js/src/love.js"></script></body></html>